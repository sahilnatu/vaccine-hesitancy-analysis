{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Shivarjun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from ast import literal_eval\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions_tweets = pd.read_csv(r\"selenium_tweets.csv\")#,converters={\"complete_urls\": literal_eval, \"about\": literal_eval})\n",
    "mentions_tweets.drop_duplicates(subset=['text'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return  WordNetLemmatizer().lemmatize(text, pos='v') #SnowballStemmer.stem\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [antidote, fauci, covid, fauci, cdcgov, demoni...\n",
       "1        [jack, abort, fetuses, aren, people, medical]\n",
       "2                                               [mike]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs = mentions_tweets['text'].astype('str').map(preprocess)\n",
    "processed_docs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 1),\n",
       " (7, 1),\n",
       " (163, 1),\n",
       " (210, 1),\n",
       " (356, 1),\n",
       " (577, 1),\n",
       " (628, 1),\n",
       " (762, 1),\n",
       " (1000, 1),\n",
       " (1072, 1),\n",
       " (1138, 1),\n",
       " (1712, 1)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running LDA using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.016*\"vaccine\" + 0.010*\"say\" + 0.009*\"like\" + 0.009*\"people\" + 0.008*\"twitter\" + 0.008*\"want\" + 0.007*\"covid\" + 0.007*\"biden\" + 0.007*\"mandate\" + 0.006*\"know\"\n",
      "Topic: 1 \n",
      "Words: 0.038*\"covid\" + 0.029*\"twitter\" + 0.020*\"people\" + 0.019*\"like\" + 0.015*\"vaccinate\" + 0.010*\"vaccine\" + 0.009*\"deaths\" + 0.009*\"die\" + 0.008*\"case\" + 0.007*\"mask\"\n"
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=2, id2word=dictionary, passes=10, workers=3,alpha =0.1, eta=0.1,\n",
    "                                      random_state=10)\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running LDA using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.008*\"covid\" + 0.007*\"people\" + 0.007*\"twitter\" + 0.007*\"vaccine\" + 0.006*\"vaccinate\" + 0.005*\"know\" + 0.005*\"say\" + 0.005*\"like\" + 0.005*\"think\" + 0.004*\"die\"\n",
      "Topic: 1 Word: 0.008*\"like\" + 0.008*\"covid\" + 0.006*\"twitter\" + 0.006*\"people\" + 0.006*\"vaccine\" + 0.005*\"want\" + 0.004*\"mask\" + 0.004*\"vaccinate\" + 0.004*\"need\" + 0.004*\"get\"\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=2, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = gensim.models.Phrases(processed_docs, min_count=5, threshold=100)\n",
    "trigram = gensim.models.Phrases(bigram[processed_docs], threshold=100)  \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
